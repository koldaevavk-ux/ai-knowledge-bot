import chromadb
from chromadb.config import Settings
import google.generativeai as genai
from groq import Groq
from typing import List, Dict
import os
from app.config import config
from app.document_loader import DocumentLoader

class AIEngine:
    def __init__(self):
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Groq
        self.groq_client = Groq(api_key=config.GROQ_API_KEY)
        
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Google Ð´Ð»Ñ embeddings
        genai.configure(api_key=config.GOOGLE_API_KEY)
        
        # ChromaDB - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ PersistentClient
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_PATH)
        self.collection_name = "knowledge_base"
        self.collection = None
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹
        self._initialize_knowledge_base()
    
    def _initialize_knowledge_base(self):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¾Ð¹ Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹"""
        try:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ get_or_create_collection, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿Ð°Ð´Ð°Ñ‚ÑŒ
            self.collection = self.chroma_client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "Corporate knowledge base"}
            )
            
            count = self.collection.count()
            if count > 0:
                print(f"âœ… ÐšÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ñ '{self.collection_name}' Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° ({count} Ñ‡Ð°Ð½ÐºÐ¾Ð²)")
                return

            print("ðŸ“š Ð‘Ð°Ð·Ð° Ð¿ÑƒÑÑ‚Ð°. ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸ÑŽ...")
            loader = DocumentLoader()
            documents = loader.load_all_documents()
            
            if not documents:
                print("âš ï¸ Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð² data/documents/")
                return
            
            embeddings = []
            texts = []
            metadatas = []
            ids = []
            
            for i, doc in enumerate(documents):
                try:
                    embedding = genai.embed_content(
                        model=config.EMBEDDING_MODEL,
                        content=doc.page_content,
                        task_type="retrieval_document"
                    )
                    embeddings.append(embedding['embedding'])
                    texts.append(doc.page_content)
                    metadatas.append(doc.metadata)
                    ids.append(f"doc_{i}")
                except Exception as e:
                    print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð° Ð´Ð»Ñ Ñ‡Ð°Ð½ÐºÐ° {i}: {e}")
                    continue
            
            if embeddings:
                self.collection.add(
                    embeddings=embeddings,
                    documents=texts,
                    metadatas=metadatas,
                    ids=ids
                )
                print(f"âœ… Ð˜Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°: {self.collection.count()} Ñ‡Ð°Ð½ÐºÐ¾Ð² Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾")
            
        except Exception as e:
            print(f"ðŸš¨ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ AI Engine: {e}")

    def get_embedding(self, text: str) -> List[float]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ embedding Ð´Ð»Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""
        result = genai.embed_content(
            model=config.EMBEDDING_MODEL,
            content=text,
            task_type="retrieval_query"
        )
        return result['embedding']
    
    def search_knowledge(self, query: str) -> List[Dict]:
        """ÐŸÐ¾Ð¸ÑÐº Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²"""
        if not self.collection or self.collection.count() == 0:
            print("âš ï¸ ÐŸÐ¾Ð¸ÑÐº Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶ÐµÐ½: ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ñ Ð¿ÑƒÑÑ‚Ð° Ð¸Ð»Ð¸ Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð°")
            return []

        try:
            query_embedding = self.get_embedding(query)
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=config.TOP_K_RESULTS
            )
            
            documents = []
            if results['documents'] and results['documents'][0]:
                for i in range(len(results['documents'][0])):
                    documents.append({
                        'content': results['documents'][0][i],
                        'metadata': results['metadatas'][0][i]
                    })
            return documents
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ°: {e}")
            return []
    
    def generate_answer(self, question: str, context_docs: List[Dict]) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Groq"""
        if not context_docs:
            return "Ð’ Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð½ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ ÑÑ‚Ð¾Ð¼Ñƒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑƒ."

        context = "\n\n---\n\n".join([
            f"Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚: {doc['metadata'].get('source', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚ÐµÐ½')}\n{doc['content']}"
            for doc in context_docs
        ])
        
        system_prompt = """Ð¢Ñ‹ â€” ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¿Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ. 
Ð£ÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº. Ð‘ÑƒÐ´ÑŒ ÐºÑ€Ð°Ñ‚Ð¾Ðº."""

        user_prompt = f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n{context}\n\nÐ’Ð¾Ð¿Ñ€Ð¾Ñ: {question}"

        try:
            response = self.groq_client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {str(e)}"
    
    def answer_question(self, question: str) -> str:
        relevant_docs = self.search_knowledge(question)
        return self.generate_answer(question, relevant_docs)
